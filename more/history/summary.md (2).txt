# [Getting started | Kubernetes](https://kubernetes.io/docs/setup/)

## Yellow

- Several Kubernetes components such as kube-apiserver or kube-proxy can also be deployed as container images within the cluster.

---

Created with Super Simple Highlighter. ©2010-24 [Dexterous Logic software](https://www.dexterouslogic.com/)
# [Production environment | Kubernetes](https://kubernetes.io/docs/setup/production-environment/)

## Yellow

- Creating a highly available cluster means considering: Separating the control plane from the worker nodes. Replicating the control plane components on multiple nodes. Load balancing traffic to the cluster’s API server. Having enough worker nodes available, or able to quickly become available, as changing workloads warrant it.
- Before building a Kubernetes production environment on your own, consider handing off some or all of this job to Turnkey Cloud Solutions providers or other Kubernetes Partners. Options include: Serverless: Just run workloads on third-party equipment without managing a cluster at all. You will be charged for things like CPU usage, memory, and disk requests. Managed control plane: Let the provider manage the scale and availability of the cluster's control plane, as well as handle patches and upgrades. Managed worker nodes: Configure pools of nodes to meet your needs, then the provider makes sure those nodes are available and ready to implement upgrades when needed. Integration: There are providers that integrate Kubernetes with other services you may need, such as storage, container registries, authentication methods, and development tools.
- Production control plane
- Manage certificates
- Configure load balancer for apiserver
- Separate and backup etcd service
- Create multiple control plane systems
- running control plane services as pods in Kubernetes ensures that the replicated number of services that you request will always be available. The scheduler should be fault tolerant, but not highly available. Some deployment tools set up Raft consensus algorithm to do leader election of Kubernetes services. If the primary goes away, another service elects itself and take over.
- Span multiple zones: If keeping your cluster available at all times is critical, consider creating a cluster that runs across multiple data centers, referred to as zones in cloud environments. Groups of zones are referred to as regions. By spreading a cluster across multiple zones in the same region, it can improve the chances that your cluster will continue to function even if one zone becomes unavailable.
- Production worker nodes
- Configure nodes: Nodes can be physical or virtual machines. If you want to create and manage your own nodes, you can install a supported operating system, then add and run the appropriate Node services. Consider: The demands of your workloads when you set up nodes by having appropriate memory, CPU, and disk speed and storage capacity available. Whether generic computer systems will do or you have workloads that need GPU processors, Windows nodes, or VM isolation. Validate nodes: See Valid node setup for information on how to ensure that a node meets the requirements to join a Kubernetes cluster. Add nodes to the cluster: If you are managing your own cluster you can add nodes by setting up your own machines and either adding them manually or having them register themselves to the cluster’s apiserver. See the Nodes section for information on how to set up Kubernetes to add nodes in these ways. Scale nodes: Have a plan for expanding the capacity your cluster will eventually need. See Considerations for large clusters to help determine how many nodes you need, based on the number of pods and containers you need to run. If you are managing nodes yourself, this can mean purchasing and installing your own physical equipment. Autoscale nodes: Read Cluster Autoscaling to learn about the tools available to automatically manage your nodes and the capacity they provide. Set up node health checks: For important workloads, you want to make sure that the nodes and pods running on those nodes are healthy. Using the Node Problem Detector daemon, you can ensure your nodes are healthy.
- Taking on a production-quality cluster means deciding how you want to selectively allow access by other users. In particular, you need to select strategies for validating the identities of those who try to access your cluster (authentication) and deciding if they have permissions to do what they are asking (authorization):
- Authentication: The apiserver can authenticate users using client certificates, bearer tokens, an authenticating proxy, or HTTP basic auth.
- Using plugins, the apiserver can leverage your organization’s existing authentication methods, such as LDAP or Kerberos.
- Authorization: When you set out to authorize your regular users, you will probably choose between RBAC and ABAC authorization.
- Role-based access control (RBAC): Lets you assign access to your cluster by allowing specific sets of permissions to authenticated users. Permissions can be assigned for a specific namespace (Role) or across the entire cluster (ClusterRole). Then using RoleBindings and ClusterRoleBindings, those permissions can be attached to particular users.
- Attribute-based access control (ABAC): Lets you create policies based on resource attributes in the cluster and will allow or deny access based on those attributes. Each line of a policy file identifies versioning properties (apiVersion and kind) and a map of spec properties to match the subject (user or group), resource property, non-resource property (/version or /apis), and readonly.
- Set the authorization mode: When the Kubernetes API server (kube-apiserver) starts, supported authorization modes must be set using an --authorization-config file or the --authorization-mode flag.
- For example, that flag in the kube-adminserver.yaml file (in /etc/kubernetes/manifests) could be set to Node,RBAC.
- Webhooks and other special authorization types need to be enabled by adding Admission Controllers to the API server.
- Set namespace limits: Set per-namespace quotas on things like memory and CPU.
- Prepare for DNS demand
- Create additional service accounts: User accounts determine what users can do on a cluster, while a service account defines pod access within a particular namespace. By default, a pod takes on the default service account from its namespace.

---

Created with Super Simple Highlighter. ©2010-24 [Dexterous Logic software](https://www.dexterouslogic.com/)